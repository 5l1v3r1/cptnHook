#! /usr/bin/env python

# Any reference to igprof-analyze is not intentional ;-)

import sys
import os
import struct
import argparse
import gzip
import array
import subprocess
import xml.etree.ElementTree as ET

#------------------------------------------------------------------------------

def getArgs():
    '''Prepare the argumnet parser'''
    p = argparse.ArgumentParser(description='Usage: cptnhook-analyse [args] profileDirectory.')
    p.add_argument('profileDir', nargs='+', help='The directory where the profile is stored.')
    p.add_argument('--root', action='store_true', default = '', help='Create ROOT output.')
    return p.parse_args()

#------------------------------------------------------------------------------

frameNamesCache = {}
def demangleFrameName(frameName):
    '''Demangle a name. This happens in two steps.
    1) With the addr2line utility if the name of a library is detected
    2) With c++filt if the name starts with "_"
    POTENTIAL OPTIMISATION: use c++filt once for all names
    '''
    if frameNamesCache.has_key(frameName): return frameNamesCache[frameName]
    rawName=frameName   
    # Case 1: it is of the form bla/bla/pluginSimulation.so(+0xab6c7a)
    if ".so(+" in frameName:
        libName,offset = frameName.split("(+")
        offset=offset[:-1] # remove trailing )
        #cmdOut = subprocess.check_output(["addr2line", "-e", libName, "-fp", offset ])
        #frameName = cmdOut.split(" ")[0]
    # Case 2: it is a normal mangled name
    if len(frameName)>0 and frameName[0] == '_':
        frameName = subprocess.check_output(["c++filt", frameName])
    frameNamesCache[rawName]=frameName
    return frameName if len(frameName)==0 or frameName[-1] != '\n' else frameName[:-1]

def demangleBackTrace(btString, newline):
    '''This is a proxy to the function demangling a single name
    Potentially, this could be parallelised with Pool.map
    '''
    rawFrameList = btString.split("`")[:-1]
    demangledFrameList = map(demangleFrameName,rawFrameList)
    return newline.join(demangledFrameList)

def getHashBTPairs(profileDir, newline = "\n"):
    '''Create a vector of backtraces to be written on file'''
    tree = ET.parse(profileDir+'/backtraceMap.xml')
    root = tree.getroot()
    hashBTList=[]
    print "*** Processing stack traces."
    nentries=0
    for bt in root.iter('bt'):
        nentries+=1
        if 0 == nentries%10000 : print "   %s stacktraces analysed." %nentries
        btStr =  bt.get('val')
        btStr = demangleBackTrace(btStr,newline)
        theHash =  int(bt.get('hash'))
        hashBTList.append([theHash,btStr])
        
    hashBTList.sort()
    return hashBTList 

def parseBTVector(profileDir):
    '''Create a vector of backtraces to be written on file'''
    import ROOT
    hashBTList = getHashBTPairs(profileDir)    
    print "*** Filling C++ data structure."
    btVector = ROOT.std.vector('string')()
    btVector.reserve(len(hashBTList))
    for btHash,btStr in hashBTList:
        #print btHash,btStr
        btVector.push_back(btStr)
    return btVector

class ROOTAnalyzer:
    def __init__(self):
        self.__trees = []
        self.__inputVal = None
        self.__hashVal = None
    def Initialize(self, compressedFileName):
        isDp = ".dp." in compressedFileName
        precisionMark = ".dp" if isDp else ".sp"
        treeName = compressedFileName[:compressedFileName.index(precisionMark)]      
        t = ROOT.TTree(treeName, treeName)
        self.__hashVal = array.array('I', [0])
        self.__inputVal = array.array('d' if isDp else 'f', [0.])        
        t.Branch("value", self.__inputVal, "value/%s" % 'D' if isDp else 'F')
        t.Branch("hash", self.__hashVal, "hash/i")
        self.__curTree = t
        self.__trees.append(t)
    def Execute(self,val,theHash):        
        self.__inputVal[0] = val
        self.__hashVal[0] = theHash
        t.Fill()        
    def Finalize(self):
        pass
    def GetTrees(self):
        return self.__trees

class VanillaAnalyzer:
    def __init__(self):
        self.__functionData = {} # key fName, val [[N,m,M,s],...,[N,m,M,s]]
        self.__curFunName = None
        self.__curNs = {}
        self.__curMins = {}
        self.__curMaxs = {}
    def Initialize(self, compressedFileName):
        self.__curFunName = compressedFileName.split(".")[0]
        self.__functionData[self.__curFunName] = []        
    def Execute(self,val,theHash):
        # This hash is already present
        if self.__curNs.has_key(theHash):
           self.__curNs[theHash]+=1
           if self.__curMins[theHash] > val : self.__curMins[theHash]=val
           if self.__curMaxs[theHash] < val : self.__curMaxs[theHash]=val
        else:
           self.__curNs[theHash]=1
           self.__curMins[theHash]=val
           self.__curMaxs[theHash]=val
    def Finalize(self):
        curData = []
        for h, N in self.__curNs.items():
            curData.append([N,self.__curMins[h],self.__curMaxs[h],h])
        curData.sort(reverse=True) # the higher, the more interesting!
        self.__functionData[self.__curFunName] = curData
        self.__curNs = {}
        self.__curMins = {}
        self.__curMaxs = {}        
    def GetData(self):
       return self.__functionData

def loopOnData(profileDir, analyzer):
    print "*** Start looping on compressed files ..."
    compressedFileNames = filter(lambda s: s.endswith("hook.gz") , os.listdir(profileDir))
    for compressedFileName in compressedFileNames:        
        isDp = ".dp." in compressedFileName
        precisionMark = ".dp" if isDp else ".sp"                  
       
        analyzer.Initialize(compressedFileName)
       
        fpSize = 8 if isDp else 4
        blockSize = fpSize + 4 # fp + unsigned int
        dataDescr = 'dI' if isDp else 'fI'       
        
        # loop on the entries
        nentries = 0
        with gzip.open(profileDir+"/"+compressedFileName, 'rb') as compressedFile:
            while True:
                # Here reading in big chuncks does not make any difference in speed
                block = compressedFile.read(blockSize)              
                if not block: break
                val, theHash = struct.unpack_from(dataDescr, block)
                analyzer.Execute(val, theHash)
                nentries+=1
                if 0 == nentries%1000000 : print "   %s entries written." %nentries
                if nentries == 100000: break
            analyzer.Finalize()
    return analyzer

#def getTrees(profileDir):
    #'''Loop over compressed files and fill a tree per function.
    #It could be optimised reading more entries at the time'''
    #import ROOT
    #trees=[]
    #compressedFileNames = filter(lambda s: s.endswith("hook.gz") , os.listdir(profileDir))
    #for compressedFileName in compressedFileNames:
        #print "*** Analysing %s ..." %compressedFileName      
        #isDp = ".dp." in compressedFileName
        #precisionMark = ".dp" if isDp else ".sp"        
        
        #treeName = compressedFileName[:compressedFileName.index(precisionMark)]      
        #t = ROOT.TTree(treeName, treeName)
        #hashVal = array.array('I', [0])
        #inputVal = array.array('d' if isDp else 'f', [0.])        
        #t.Branch("value", inputVal, "value/%s" % 'D' if isDp else 'F')
        #t.Branch("hash", hashVal, "hash/i")
       
        #fpSize = 8 if isDp else 4
        #blockSize = fpSize + 4 # fp + unsigned int
        #dataDescr = 'dI' if isDp else 'fI' 
        
        ## loop on the entries
        #nentries = 0
        #with gzip.open(profileDir+"/"+compressedFileName, 'rb') as compressedFile:
            #while True:
                ## Here reading in big chuncks does not make any difference in speed
                #block = compressedFile.read(blockSize)              
                #if not block: break
                #val, theHash = struct.unpack_from(dataDescr, block)
                #inputVal[0] = val
                #hashVal[0] = theHash
                #t.Fill()
                #nentries+=1
                #if 0 == nentries%1000000 : print "   %s entries written." %nentries    
        #trees.append(t)
    #return trees
   
def analyzeROOT(profileDir):
    ''' Convert output to a ROOT file '''
    import ROOT
    ofileName = profileDir.replace("/","_")+".root"
    ofile = ROOT.TFile.Open(ofileName,"recreate")
    
    btVector = parseBTVector(profileDir)
    ofile.WriteObject(btVector, "backtraceVector")
    
    rootAna = loopOnData(profileDir, ROOTAnalyzer())

    for t in rootAna.GetTrees():
        t.Write()
        
    ofile.Close()
    return 0

def getCumulativeStats(theData):
    '''For all functions, get
    - name
    - total number of entries
    - min 
    - max
    - N distinct traces
    '''
    from operator import add
    cumStats = []
    for fcnName, theDataPerStack in theData.items():
        first = True
        theMin = 0
        theMax = 0
        N = 0
        for el in theDataPerStack:
           stackmin = el[1]
           stackmax = el[2]
           N += el[0]
           if first: 
              theMin = stackmin
              theMax = stackmax
           else:
              if theMin > stackmin: theMin = stackmin
              if theMax < stackmax: theMax = stackmax
        cumStats.append([fcnName, N, theMin, theMax, len(theDataPerStack)])
    cumStats.sort(key = lambda x: x[1],reverse=True)
    return cumStats

def formTableRow(entries, headings=False):
    sep = "th" if headings else "td"
    row = "<tr>"
    for entry in entries:
        row += '<%s align="center">%s</%s>' %(sep,entry,sep)
    row += "</tr>"
    return row
 
def formLink(name,target=None, anchor=False):
   name = str(name)
   if not target:
       target=name+".html"
   attrName = "name" if anchor else "href"
   return '<a %s="%s">%s</a>' %(attrName,target,name)

def formFooter(backTo="index"):
   s = formLink("Back to %s" %backTo , "%s.html" %backTo) if backTo!="" else ""
   return "<br><br>%s<br>\n</body></html>" %s

def formTitle(title):
   return "<html></body><h1>CptnHook Report %s</h1>\n" %title

def createStackTraces(name, reportDirName, hBtDict):
    stackSummaryName = reportDirName+"/stacktraces.html"
    pageContent = formTitle(name)
    pageContent = "<h2>Stack Summary</h2>"
    header=""
    for key in sorted(hBtDict.keys()):       
       header+="%s," %formLink(key)
       if key%10 == 0 : header+="<br>"       
       stackPage = formTitle("Stack %s"%key)
       stackPage+= "%s\n" %hBtDict[key]
       #print "-------"
       #print hBtDict[key]
       stackPage += formFooter("stacktraces")
       with open("%s/%s.html" %(reportDirName,key), "w") as ofile:
           ofile.write(stackPage)
    if header[-1] == ',': header=header[:-1]
    if header.endswith(",<br>"): header=header[:-5]+"<br>"
    
    pageContent+=header
    
    pageContent+= formFooter()
    
    with open(stackSummaryName, "w") as ofile:
        ofile.write(pageContent)
 
def createFunctions(profileDir, reportDirName, theData):
    '''We create for each function a page with a table with the five 
    values: name, N calls, min, max, stack. The last is a link to the stack.
    '''
    for function, fData in theData.items():
       pageContent = formTitle(function)
       table = '<table style="width:100%" align="center" border="1px" >\n'
       table += formTableRow(["N Calls", "Min", "Max", "Trace ID"], headings=True)
       for singleStat in fData:
           singleStat[-1] = formLink(singleStat[-1])
           table += formTableRow(singleStat)
       table += '</table>'
       pageContent += table
       pageContent += formFooter('index')
       with open(reportDirName+"/%s.html" %function, "w") as ofile:
           ofile.write(pageContent)     
 
def createIndex(name, indexName, theData):
    ''''''
    pageContent = formTitle(name)
    cumStats = getCumulativeStats(theData)
    table = '<table style="width:100%" align="center" border="1px" >\n'
    table += formTableRow(["Fcn Name","N Calls", "Min", "Max", "Distinct Traces"], headings=True)
    for singleCumStat in cumStats:
        singleCumStat[0] = formLink(singleCumStat[0])
        if singleCumStat[1] != 0:
            table += formTableRow(singleCumStat)
    table += "</table>\n"
    pageContent+=table    
    pageContent+="<br>"
    pageContent+="Click %s to inspect the stack traces.\n" % formLink("stacktraces")
    pageContent+= formFooter("")
    
    with open(indexName, "w") as ofile:
        ofile.write(pageContent)
 
def createWebReport(profileDir,theData,hBtDict):
    ''''''
    reportDirName = profileDir+"_report"
    if not os.path.exists(reportDirName): os.mkdir(reportDirName)
    
    indexName = reportDirName+"/index.html"
    createIndex(profileDir, indexName, theData)
        
    createStackTraces(profileDir, reportDirName, hBtDict)
    
    createFunctions(profileDir, reportDirName, theData)
    
 
def analyzeVanilla(profileDir):
    '''We need to produce a report with the following elements:
      - A frontpage with a table which has 5 columns: function name,
        number of calls, xmin, xmax, n stacks. The frontpage also has 
        a link to the list of stacks
      - A list of stacks, with anchors for every stack
      - For every function, a page which lists all the stacks where the 
        function is called, ordere by number of calls. For each section, 
        we report number of calls, xmin, xmax.
    The data structure to collect the data of the functions is a dictionary
    the keys of which are function names and the values of which are a list 
    of lists which contain 4 numbers: the number of calls, the min, the max
    and the stack ID.
    '''
    
    hBtPairs = getHashBTPairs(profileDir,newline="<br>\n")
    hBtDict = {}
    for h, bt in hBtPairs: hBtDict[h] = bt
    
    vanillAna = loopOnData(profileDir, VanillaAnalyzer())

    createWebReport(profileDir,vanillAna.GetData(),hBtDict)
    
    return 0
 
def analyze(profileDir, toROOT = False):
    if toROOT: return analyzeROOT(profileDir)
    else: return analyzeVanilla(profileDir)

if __name__ == "__main__":
    args = getArgs()
    retcode = analyze(profileDir = args.profileDir[0], toROOT = args.root)
    sys.exit(retcode)
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   